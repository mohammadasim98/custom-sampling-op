{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "57287a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow3d as t3d\n",
    "import numpy as np\n",
    "from dataclasses import dataclass, asdict, field\n",
    "from tqdm import trange\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "835689c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(path, batch=True, batch_size=32, cache=True, ordered=False, shuffle=False, test=False):\n",
    "    dataset = tf.data.TFRecordDataset(tf.io.gfile.glob(f\"{path}/*.tfrecords\"))\n",
    "    ignore_order = tf.data.Options()\n",
    "    if not ordered:\n",
    "        ignore_order.experimental_deterministic = False\n",
    "        \n",
    "    dataset = dataset.with_options(ignore_order)\n",
    "    \n",
    "    feature_description = {\n",
    "        'ground_truth': tf.io.FixedLenFeature([], tf.string),\n",
    "        'num': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'point_cloud1': tf.io.FixedLenFeature([], tf.string),\n",
    "        'point_cloud2': tf.io.FixedLenFeature([], tf.string),\n",
    "        'color1': tf.io.FixedLenFeature([], tf.string),\n",
    "        'color2': tf.io.FixedLenFeature([], tf.string),\n",
    "        'mask1': tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "\n",
    "    def _parse_image_function(example_proto):\n",
    "        content = tf.io.parse_single_example(example_proto, feature_description)\n",
    "        pc1 = tf.io.parse_tensor(content['point_cloud1'], tf.float32)\n",
    "        pc2 = tf.io.parse_tensor(content['point_cloud2'], tf.float32)\n",
    "        flow = tf.io.parse_tensor(content['ground_truth'], tf.float32)\n",
    "        m1 = tf.io.parse_tensor(content['mask1'], tf.bool)\n",
    "        return (pc1, pc2, flow, m1)\n",
    "    \n",
    "    dataset = dataset.map(_parse_image_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(1024)\n",
    "        \n",
    "    if batch:\n",
    "        dataset = dataset.batch(batch_size, drop_remainder=False)\n",
    "        \n",
    "    if cache:\n",
    "        dataset = dataset.cache()\n",
    "        \n",
    "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e6d0bd02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/custom-op/tensorflow3d\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd6f427",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "87fc2d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           [(None, None, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           [(None, None, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "set_conv_30 (SetConv)           ((None, 1024, 3), (N 3808        input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "set_conv_32 (SetConv)           ((None, 1024, 3), (N 3808        input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "set_conv_31 (SetConv)           ((None, 256, 3), (No 17856       set_conv_30[0][0]                \n",
      "                                                                 set_conv_30[0][1]                \n",
      "__________________________________________________________________________________________________\n",
      "set_conv_33 (SetConv)           ((None, 256, 3), (No 17856       set_conv_32[0][0]                \n",
      "                                                                 set_conv_32[0][1]                \n",
      "__________________________________________________________________________________________________\n",
      "flow_embedding_5 (FlowEmbedding ((None, 256, 3), (No 67840       set_conv_31[0][0]                \n",
      "                                                                 set_conv_31[0][1]                \n",
      "                                                                 set_conv_33[0][0]                \n",
      "                                                                 set_conv_33[0][1]                \n",
      "__________________________________________________________________________________________________\n",
      "set_conv_34 (SetConv)           ((None, 64, 3), (Non 68480       set_conv_31[0][0]                \n",
      "                                                                 flow_embedding_5[0][1]           \n",
      "__________________________________________________________________________________________________\n",
      "set_conv_35 (SetConv)           ((None, 16, 3), (Non 268032      set_conv_34[0][0]                \n",
      "                                                                 set_conv_34[0][1]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_5 (TensorFlo [(None, 256, 256)]   0           set_conv_31[0][1]                \n",
      "                                                                 flow_embedding_5[0][1]           \n",
      "__________________________________________________________________________________________________\n",
      "set_up_conv_15 (SetUpConv)      (None, 64, 256)      265472      set_conv_34[0][0]                \n",
      "                                                                 set_conv_34[0][1]                \n",
      "                                                                 set_conv_35[0][0]                \n",
      "                                                                 set_conv_35[0][1]                \n",
      "__________________________________________________________________________________________________\n",
      "set_up_conv_16 (SetUpConv)      (None, 256, 256)     217216      set_conv_31[0][0]                \n",
      "                                                                 tf_op_layer_concat_5[0][0]       \n",
      "                                                                 set_conv_34[0][0]                \n",
      "                                                                 set_up_conv_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "set_up_conv_17 (SetUpConv)      (None, 1024, 256)    168064      set_conv_30[0][0]                \n",
      "                                                                 set_conv_30[0][1]                \n",
      "                                                                 set_conv_31[0][0]                \n",
      "                                                                 set_up_conv_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "feature_propagation_5 (FeatureP (None, None, 256)    133632      input_11[0][0]                   \n",
      "                                                                 set_conv_30[0][0]                \n",
      "                                                                 set_up_conv_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, None, 128)    33408       feature_propagation_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, None, 3)      387         conv1d_10[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,265,859\n",
      "Trainable params: 1,255,107\n",
      "Non-trainable params: 10,752\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "flownet3d = t3d.models.FlowNet3D(name='flownet3d').build(input_shape1=(None, 3), input_shape2=(None, 3))\n",
    "flownet3d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "da4e2fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Settings:\n",
    "    name: str\n",
    "    lr: float=0.001\n",
    "    lr_decay: float=0.8\n",
    "    patience: int=12\n",
    "    epochs: int=1000\n",
    "    batch_size: int=32\n",
    "    def dict(self):\n",
    "        return {k: str(v) for k, v in asdict(self).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bbadc341",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_log_dir = 'logs/gradient_tape/' + current_time + '/train'\n",
    "test_log_dir = 'logs/gradient_tape/' + current_time + '/test'\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "test_summary_writer = tf.summary.create_file_writer(test_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "44fa4d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(pred, gt, mask):\n",
    "    \"\"\"\n",
    "    Compute Variational Energy Loss, and EPE\n",
    "    \"\"\"\n",
    "    \n",
    "    return tf.keras.metrics.mean_squared_error(pred, gt)\n",
    "    \n",
    "    \n",
    "\n",
    "def train(data, model, settings):\n",
    "    \"\"\"\n",
    "    Training Loop\n",
    "    \"\"\"\n",
    "\n",
    "    # Fetch config from settings\n",
    "    batch_size = settings.batch_size\n",
    "    pbar = trange(settings.epochs)\n",
    "    optimiser = tf.keras.optimizers.Adam(settings.lr)\n",
    "    patience = settings.patience\n",
    "    lr_decay = settings.lr_decay\n",
    "    train_dataset = build_dataset('./../assets/train', batch_size=batch_size)\n",
    "    val_dataset = build_dataset('./../assets/test', batch_size=batch_size)\n",
    "    \n",
    "    losses = []\n",
    "    counter = 0\n",
    "    history = {'train': {'mse': []}, 'val': {'mse': []}, 'lr':[]}\n",
    "    for i in pbar:\n",
    "        iter_losses = []\n",
    "        history['lr'].append(optimiser.lr.numpy())\n",
    "        for batch in data[0]:\n",
    "            loss = train_step(batch, model, optimiser, train=True)\n",
    "            iter_losses.append(loss)\n",
    "    \n",
    "        epoch_loss = tf.reduce_mean(iter_losses).numpy()\n",
    "        tf.summary.scalar('train_loss', epoch_loss, step=i)\n",
    "        history['train']['mse'].append(epoch_loss)\n",
    "        if(min(history['train']['mse']) < epoch_loss):\n",
    "            counter += 1\n",
    "            \n",
    "        else:\n",
    "            counter = 0\n",
    "            model.save('ckpt.h5')\n",
    "            \n",
    "        if(patience is not None and counter == patience):\n",
    "            counter = 0\n",
    "            optimiser.lr.assign(optimiser.lr.numpy()*lr_decay)\n",
    "            print(f\"Learning rate decayed to: {optimiser.lr.numpy()}, Minimum (mse) was: ({min(history['train']['mse'])})\")\n",
    "       \n",
    "        val_losses = []\n",
    "        if(data[1] is not None):\n",
    "            for batch in data[1]:\n",
    "                loss = train_step(batch, model, optimiser, train=False)\n",
    "                iter_losses.append(loss)\n",
    "                \n",
    "        val_epoch_loss = tf.reduce_mean(iter_losses).numpy()\n",
    "        tf.summary.scalar('val_loss', val_epoch_loss, step=i)\n",
    "        history['val']['mse'].append(val_epoch_loss)\n",
    "        pbar.set_description(f\"train_mse:  {epoch_loss}, val_mse: {val_epoch_loss}, patience_count: {counter}\")\n",
    "        \n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "afdf6bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(batch, model, optimiser, train=True):\n",
    "    \"\"\" \n",
    "    Single Forward and Backpropagation Step\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.GradientTape(persistent=False) as tape:\n",
    "        pred = model((batch[0], batch[1]))\n",
    "        loss = compute_loss(pred, batch[2], batch[3])\n",
    "    \n",
    "    if(train):\n",
    "        grad = tape.gradient(loss, model.trainable_variables)\n",
    "        optimiser.apply_gradients(zip(grad, model.trainable_variables), experimental_aggregate_gradients=False)\n",
    "        \n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "731aac6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = Settings(\n",
    "    name='model.h5',\n",
    "    lr=0.001, #0.0008\n",
    "    lr_decay=0.8,\n",
    "    patience=12,\n",
    "    epochs=151,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c533178c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a2fd5fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/151 [01:12<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-c523fb8b8094>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflownet3d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-107-e538488262c6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data, model, settings)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimiser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0miter_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model, history = train((train_dataset, val_dataset), flownet3d, settings)\n",
    "model.save(settings.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e0844023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 11927), started 0:00:55 ago. (Use '!kill 11927' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b3902c05a1ff46f8\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b3902c05a1ff46f8\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir logs/gradient_tape --host 127.0.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "766101a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: kill: No such process\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!kill 11927"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03573902",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
